{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# subprocess.run(\"ollama serve\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ollama\n",
    "# #Then everytime you want to chat\n",
    "# response = ollama.chat(model='llama3.2', messages=[\n",
    "#   {\n",
    "#     'role': 'user',\n",
    "#     'content': 'Why is the sky blue?',\n",
    "#   },\n",
    "# ])\n",
    "# print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import AzureOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # read local .env file\n",
    "OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "# from streamlit_extras.add_vertical_space import add_vertical_space\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.chat_message_histories import StreamlitChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "# from langchain_openai import AzureOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = AzureOpenAIEmbeddings(\n",
    "#     model=\"text-embedding-3-large\",\n",
    "#     deployment= 'genai-gpt-35-turbo',\n",
    "#     # dimensions: Optional[int] = None, # Can specify dimensions with new text-embedding-3 models\n",
    "#     azure_endpoint=OPENAI_API_BASE, #\"https://<your-endpoint>.openai.azure.com/\", If not provided, will read env variable AZURE_OPENAI_ENDPOINT\n",
    "#     api_key=OPENAI_API_KEY, # Can provide an API key directly. If missing read env variable AZURE_OPENAI_API_KEY\n",
    "#     openai_api_version=OPENAI_API_VERSION, # If not provided, will read env variable AZURE_OPENAI_API_VERSION\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to process text data in chunks and add to the FAISS index\n",
    "# def process_in_chunks(text_data, chunk_size, embeddings, index_name):\n",
    "#     # Check if the index already exists\n",
    "#     if os.path.exists(f\"{index_name}.faiss\") and os.path.exists(f\"{index_name}.pkl\"):\n",
    "#         vectorstore = FAISS.load_local(index_name, embeddings)\n",
    "#         print(\"Loaded existing FAISS index.\")\n",
    "#     else:\n",
    "#         vectorstore = None\n",
    "    \n",
    "#     for i in range(0, len(text_data), chunk_size):\n",
    "#         chunk = text_data[i:i + chunk_size]\n",
    "#         try:\n",
    "#             print(f\"Processing chunk {i // chunk_size + 1}\")\n",
    "#             temp_vectorstore = FAISS.from_texts(chunk, embeddings)\n",
    "            \n",
    "#             if vectorstore:\n",
    "#                 vectorstore.merge_from(temp_vectorstore)\n",
    "#             else:\n",
    "#                 vectorstore = temp_vectorstore\n",
    "            \n",
    "#             # Save the updated FAISS index after processing each chunk\n",
    "#             vectorstore.save_local(index_name)\n",
    "#             print(f\"Chunk {i // chunk_size + 1} processed and index saved.\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing chunk {i}: {e}\")\n",
    "        \n",
    "#         time.sleep(1)  # Sleep to respect the rate limit\n",
    "    \n",
    "#     return vectorstore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory loaded\n"
     ]
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=False)\n",
    "\n",
    "# Load documents\n",
    "loader = DirectoryLoader(\"./input-data\", glob=\"**/*.txt\")\n",
    "print(\"Directory loaded\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=300,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created successfully\n",
      "FAISS index saved locally\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index\n",
    "vectorstore = FAISS.from_documents(texts, embeddings,)\n",
    "\n",
    "print(\"FAISS index created successfully\")\n",
    "\n",
    "# Save the index locally\n",
    "vectorstore.save_local(\"my_faiss_index\")\n",
    "\n",
    "print(\"FAISS index saved locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved index\n",
    "loaded_vectorstore = FAISS.load_local(\"my_faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create retriever\n",
    "retriever = loaded_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # read local .env file\n",
    "OPENAI_API_TYPE = os.getenv('OPENAI_API_TYPE')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_BASE = os.getenv('OPENAI_API_BASE')\n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\750040697\\AppData\\Local\\Temp\\ipykernel_18016\\3925094818.py:1: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  llm = AzureChatOpenAI(openai_api_base=OPENAI_API_BASE,\n"
     ]
    }
   ],
   "source": [
    "llm = AzureChatOpenAI(openai_api_base=OPENAI_API_BASE,\n",
    "                        openai_api_version=OPENAI_API_VERSION,\n",
    "                        openai_api_key=OPENAI_API_KEY,\n",
    "                        openai_api_type=OPENAI_API_TYPE,\n",
    "                        #deployment_name = 'genai-gpt-4-32k',\n",
    "                        #model_name = 'gpt-4-32k')\n",
    "                        deployment_name = 'genai-gpt-35-turbo',\n",
    "                        model_name = 'gpt-35-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create prompt template\n",
    "template = \"\"\"<bos><start_of_turn>user\n",
    "You are a sales inquiry assistant specializing in rebates, market share, promotions, and payouts. Answer the question based only on the following context and provide a meaningful response. \n",
    "Write in full sentences with correct spelling and punctuation. Use bullet points or numbered lists when appropriate.\n",
    "If the context doesn't contain the answer, politely state that you don't have the specific information and suggest contacting the sales department for more details.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "ANSWER:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template )\n",
    "\n",
    "# # Modify the rag_chain to return the result instead of streaming\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All affiliation change requests must be accompanied by documentation (such as an email) from the account requesting such. Please include account number, group to be affiliated with, and quarter to begin new affiliation. Alternatively, the account can send the request to RA VISUS SalesInquir@its.jnj.com directly. Ensure that they include SAP, date of affiliation change, and group to be affiliated with. An account must join, or have joined, the requested RfP group on or before the last day of the first month of the quarter to qualify for a rebate.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"RfP affiliation change request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./car_dummy.csv')\n",
    "df_columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agent = create_pandas_dataframe_agent(llm, df, verbose=True,allow_dangerous_code=True,max_iterations = 3)\n",
    "\n",
    "# Create embeddings for the vector store\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=False)\n",
    "\n",
    "# Load the saved index\n",
    "loaded_vectorstore = FAISS.load_local(\"my_faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Create retriever\n",
    "retriever = loaded_vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# Create prompt template\n",
    "template = \"\"\"<bos><start_of_turn>user\n",
    "You are a sales inquiry assistant specializing in rebates, market share, promotions, and payouts. Answer the question based on the following context, including retrieved documents and relevant employee data when applicable. \n",
    "Write in full sentences with correct spelling and punctuation. Use bullet points or numbered lists when appropriate.\n",
    "If the context doesn't contain the specific information, politely state that you don't have the answer and suggest contacting the sales department for further details.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "DATAFRAME INFO: {dataframe_info} dataframe columns = {df_columns}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "<end_of_turn>\n",
    "<start_of_turn>model\n",
    "ANSWER:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"FAQ for sales Inquiries\",\n",
    "        func=retriever.get_relevant_documents,\n",
    "        description=\"\"\"\n",
    "        Useful for when you need to answer questions about sales Inquiries.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Roster\",\n",
    "        func=df_agent.run,\n",
    "        description=f\"\"\"\n",
    "        Useful for when you need to answer questions about grouping, enrollment, location, eligibility, fell out, preferred, program, independent, roster, trackers, dashboard, joined, affiliation, fallen out, fallen off\n",
    "        'rebate','market share','promotion','payout'  \n",
    "        data stored in pandas dataframe 'df'. \n",
    "        'df' has the following columns: {df_columns}.\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversational memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom agent prompt with friendly HR assistant context\n",
    "agent_kwargs = {\n",
    "    'prefix': f'''You are a sales inquiry assistant specializing in rebates, market share, promotions, and payouts. Answer the question based on the following context, including retrieved documents and relevant employee data when applicable. \n",
    "Write in full sentences with correct spelling and punctuation. Use bullet points or numbered lists when appropriate.\n",
    "If the context doesn't contain the specific information, politely state that you don't have the answer and suggest contacting the sales department for further details. You have access to the following tools:'''\n",
    "}\n",
    "\n",
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    agent_kwargs=agent_kwargs,\n",
    "    handle_parsing_errors=True,\n",
    "    early_stopping_method=\"generate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out if the account exists in our system or if it is a new customer\n",
      "Action: Roster\n",
      "Action Input: Account name or ID\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: It's not clear what account name or ID is being referred to. Need more information.\n",
      "Final Answer: N/A\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mN/A\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check if the account is a new customer or already exists in our system\n",
      "Action: Roster\n",
      "Action Input: Account name or ID\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: This question is unclear. It is not clear what account is being referred to.\n",
      "Final Answer: N/A\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mN/A\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can't find any information about the account in our Roster, so it might be a new customer\n",
      "Action: FAQ for sales Inquiries\n",
      "Action Input: \"How do I add a new customer to the RfP Tracker?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[Document(metadata={'source': 'input-data\\\\inquiries.txt', 'start_index': 0}, page_content='RfP Alignments and Affiliations\\n\\nAccount is not found on the RfP Tracker\\n\\nAn account will not appear on the RfP Tracker if it has $0 in sales for the current quarter or if it is not an active member of any RfP group.\\n\\nThere are known issues when searching by account name in the RfP tracker. Please try searching by account number.\\n\\nOption to Send Inquiry\\n\\nSAP is missing or incorrectly aligned on the RfP Tracker\\n\\nSAPs are aligned to RfP locations by address. Please ensure the information in our system matches what the RfP group is reporting. Addresses in our system can be updated by contacting New Accounts.\\n\\nOption to Send Inquiry\\n\\nRfP location is grouped incorrectly\\n\\nRfP location groupings are determined by the RfP group (i.e. GPO or Lease Franchise). Please contact the Group Headquarters to resolve grouping issues.\\n\\nThere should not be an option to Send Inquiry here\\n\\nRfP affiliation change request.\\n\\nAll affiliation change requests must be accompanied by documentation (such as an email) from the account requesting such. Please include account number, group to be affiliated with, and quarter to begin new affiliation.\\n\\nAlternatively, the account can send the request to RA\\n\\nVISUS\\n\\nSalesInquir@its.jnj.com directly. Ensure that they include SAP, date of affiliation change, and group to be affiliated with.\\n\\nAn account must join, or have joined, the requested RfP group on or before the last day of the first month of the quarter to qualify for a rebate.'), Document(metadata={'source': 'input-data\\\\inquiries.txt', 'start_index': 4745}, page_content='You may view quarterly RFP history in the Preferred RFP Tracker in the ‘Rebate History’ section. ACUVUE Share and baseline share will continue to update in the ‘Rebate’ section with the latest data from GPN, based on customer’s POS entries, on a weekly basis. Please continue to reference the most recent updated through dates in the top right of the Preferred RFP Tracker. The ACUVUE® Dashboard Powered by GPN® continues to be updated on a daily basis and can provide up to date information on current effective year to date share.\\n\\nWhile the baseline share value might change throughout a given quarter for the reasons noted above, as outlined in the Preferred agreement, for all POS and share data “calculations will be computed based solely on the data as reflected at the close of the quarter”.\\n\\nGPN and JJV do not have the ability to alter any POS or share data as it comes in directly from the customer’s practice management system. It is the customer’s responsibility to ensure the data being reported from their POS system is accurate and timely. Per the    Preferred T&Cs, Section 7 and Section 14(d), the account must have GPN installed at each affiliated location and the account must capture point of sale data at each individual affiliated location.'), Document(metadata={'source': 'input-data\\\\inquiries.txt', 'start_index': 3615}, page_content='If it is myAPP, Alliance or LF ; Refer to the CX team\\n\\nOption to Send Inquiry\\n\\nName or address on payment is incorrect\\n\\nIf the account is a member of a GPO please contact their respective headquarters to resolve all check related issues.\\n\\nMyApp address information is sourced from our system. Please contact New Accounts to resolve this issue.\\n\\nReissue check : If it is myAPP, Alliance or LF ; Refer to the CX team\\n\\nOption to Send Inquiry\\n\\nPreferred Baseline Issues Point of sale and share data is provided by GPN, based on customer POS entries, and updated on the Preferred RFP Tracker on a weekly basis. The information in the Preferred RFP Tracker is updated weekly and includes POS information through the previous week. In most instances, the baseline information should remain consistent since it is based on historical information, however, there are a number of different factors that can change the baseline share data including but not limited to: changes in office sales/POS system, roster affiliation changes (i.e. adding/removing locations), and timing of when data is refreshed across the various dashboards/tools.'), Document(metadata={'source': 'input-data\\\\inquiries.txt', 'start_index': 8286}, page_content='Rebate Percentage Errors in the Rfp Tracker This is only a reporting issue in the Rfp tracker and did (does) not affect the rebates earned by these accounts. The team is aware of this and are working to have this resolved. The Q2 percentages have been corrected effective 9/8/21. Please let me know if you have questions.\\n\\nPreferred Benefits eligibility *Attach the Preferred eligibility* Please find attached the Preferred Benefits eligibility file. Please refer to the customer activation dashboard to check eligibility for benefits or check with your DBM if you have doubts. Please let me know if you have further questions.\\n\\nExplanation of rebates for non-Partner tier accounts. Preferred diamond tier accounts are entitled to the maximum of 20% of their YTD revenue or 50% of rfp sales growth less the estimated rebate earned previously in the YTD period. Current YTD Rev: $67,213.07 Previous YTD Rev: $65,402 YTD Growth: $ 1,811.07 RAS growth rebate: 0.5*$1,811.07 =  $905.5 Rebate: 0.2* $67,213.07= $13,442.61 Max Pref Rebate = $13,454.25 Q1 Est. Rebate = $3,588.61 Q2 Est Rebate = $0.0 Q3 Est Rebate = $3,336.6 True-up = $13,442.61- $3,588.61- $0.00 - $3,336.6= $6,517.4 Please let me know if you have further questions. We are in the process of finalizing Q4 end quarter status. Once completed, the status of account will be communicated, and their eligible benefits will be updated on the activation dashboard.'), Document(metadata={'source': 'input-data\\\\inquiries.txt', 'start_index': 1189}, page_content='VISUS\\n\\nSalesInquir@its.jnj.com directly. Ensure that they include SAP, date of affiliation change, and group to be affiliated with.\\n\\nAn account must join, or have joined, the requested RfP group on or before the last day of the first month of the quarter to qualify for a rebate.\\n\\nAffiliation change requests will be honored until the last day of the quarter.\\n\\nThe RfP tracker will reflect current quarter affiliations on the 4th day of the third month of the quarter or 2\\n\\n3 days after notice is received if received after the 4th day of the third month of the quarter.\\n\\nAffiliations in Intouch are synched with the RfP tracker once a quarter at the end of the quarter.\\n\\nOption to Send Inquiry\\n\\nSign up for MyApp\\n\\nContact New Accounts to set the Account to “Independent”.\\n\\nHave the account sign up on the MyApp portal/ reach out to SA\\n\\nvisus\\n\\nviseyesite@its.jnj.com to enroll manually.\\n\\nThe deadline for a given quarter is the last day of the first month of the quarter.\\n\\nMyApp groupings are determined by a common Payer account. An account with a Payer who is not enrolled in MyApp will not be eligible to receive a rebate through MyApp. Payer alignments are handled by New Accounts.\\n\\nThere should not be an option to Send Inquiry here\\n\\nSign up for Alliance\\n\\nHave the account sign up on the Acuvue Alliance portal/ reach out to SA\\n\\nvisus\\n\\nviseyesite@its.jnj.com to enroll manually.\\n\\nThe deadline for a given quarter is the last day of the first month of the quarter.')]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can advise the sales team that the account may be a new customer and they should contact New Accounts to add them to the RfP Tracker.\n",
      "Final Answer: The account may be a new customer and the sales team should contact New Accounts to add them to the RfP Tracker.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The account may be a new customer and the sales team should contact New Accounts to add them to the RfP Tracker.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Account is not found on the RfP Tracker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to check if a question is related to structured data in the DataFrame\n",
    "# def is_dataframe_question(query):\n",
    "#     related_keywords = ['rebate', 'market share', 'promotion', 'payout']\n",
    "#     return any(keyword in query.lower() for keyword in related_keywords)\n",
    "\n",
    "# # Main chatbot logic\n",
    "# def chatbot(query):\n",
    "#     # Retrieve relevant documents from the vector store (always needed)\n",
    "#     context = retriever.get_relevant_documents(query)\n",
    "#     context_str = \"\\n\".join([doc.page_content for doc in context])\n",
    "\n",
    "#     # Check if the query is related to the pandas DataFrame\n",
    "#     if is_dataframe_question(query):\n",
    "#         # Query the pandas DataFrame agent\n",
    "#         dataframe_info = df_agent.run(query)\n",
    "#     else:\n",
    "#         # If it's not related to the DataFrame, leave dataframe_info empty\n",
    "#         dataframe_info = \"No relevant structured data found.\"\n",
    "\n",
    "#     # Create input for the LLM with both context and DataFrame info\n",
    "#     final_input = template.format(context=context_str, dataframe_info=dataframe_info, question=query)\n",
    "\n",
    "#     # Get response from the LLM\n",
    "#     response = llm_for_pandas(final_input)\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a question is related to structured data in the DataFrame\n",
    "# def is_dataframe_question(query):\n",
    "#     related_keywords = ['rebate', 'market share', 'promotion', 'payout']\n",
    "#     return any(keyword in query.lower() for keyword in related_keywords)\n",
    "\n",
    "# Main chatbot logic\n",
    "def chatbot(query):\n",
    "    # Retrieve relevant documents from the vector store (always needed)\n",
    "    context = retriever.get_relevant_documents(query)\n",
    "    context_str = \"\\n\".join([doc.page_content for doc in context])\n",
    "\n",
    "    # # Check if the query is related to the pandas DataFrame\n",
    "    # if is_dataframe_question(query):\n",
    "        # Query the pandas DataFrame agent\n",
    "    \n",
    "    # Always run the pandas DataFrame agent query, with error handling\n",
    "    try:\n",
    "        dataframe_info = df_agent.run(query)\n",
    "    except Exception as e:\n",
    "        # Handle the error and provide a default response\n",
    "        dataframe_info = f\"No relevant structured data found in DataFrame\"\n",
    "\n",
    "    # Create input for the LLM with both context and DataFrame info\n",
    "    final_input = template.format(context=context_str, dataframe_info=dataframe_info, df_columns= df_columns, question=query)\n",
    "\n",
    "    # Get response from the LLM\n",
    "    response = llm.invoke(final_input)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: We need more information to answer this question. What account are we looking for? Is it in a specific column of the dataframe?\n",
      "Action: Check if a specific account is in the `RFP_Key` column of the dataframe\n",
      "Action Input: `df[df['RFP_Key'] == 'account number']`\u001b[0mCheck if a specific account is in the `RFP_Key` column of the dataframe is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mWe need to find all unique values in the `RFP_Key` column to see if the account is present.\n",
      "Action: Use the `unique()` method to get all unique values in the `RFP_Key` column\n",
      "Action Input: `df['RFP_Key'].unique()`\u001b[0mUse the `unique()` method to get all unique values in the `RFP_Key` column is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3mWe need to search for the account in the `RFP_Key` column using a boolean expression.\n",
      "Action: Use boolean indexing to check if the account is present in the `RFP_Key` column\n",
      "Action Input: `df[df['RFP_Key'] == 'account number']`\u001b[0mUse boolean indexing to check if the account is present in the `RFP_Key` column is not a valid tool, try one of [python_repl_ast].\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='An account will not appear on the RfP Tracker if it has $0 in sales for the current quarter or if it is not an active member of any RfP group. There are known issues when searching by account name in the RfP tracker. Please try searching by account number. If the issue persists, please contact the sales department for further assistance.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1763, 'total_tokens': 1837, 'completion_tokens_details': None}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a65e5301-9e2d-4a94-a1a1-613a42a8989c-0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot('Account is not found on the RfP Tracker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
